{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **AIM:**\n",
        "To achieve the tasks using Spark SQL and integrate with machine learning algorithms.\n",
        "* Identify the country with the highest purchase.\n",
        "* Count the number of unique customers from each country.\n",
        "* Calculate the maximum quantity purchased by each customer.\n",
        "* Compute the maximum and minimum sales within a specified date range (01.10.24 to 15.10.24).\n",
        "* Calculate the total sales across all countries.\n",
        "\n",
        "Machine Learning Integration:\n",
        "\n",
        "* Use ML algorithms to predict future sales or customer purchasing behavior based on historical data.\n",
        "* Build a regression model (e.g., linear regression) to forecast total sales.\n"
      ],
      "metadata": {
        "id": "5ZehS_bV9Fym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Spark SQL for Analysis**"
      ],
      "metadata": {
        "id": "WMeRTDJv7VMt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj_aQ6Hs2pJ8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, sum, max, min, countDistinct, to_date\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"E-commerce Analysis with Spark SQL\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "JUos7TNV5RuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a pandas DataFrame\n",
        "file_path = \"/content/Online Retail.xlsx\"\n",
        "pdf = pd.read_excel(file_path) # Read the Excel file into a pandas DataFrame 'pdf'"
      ],
      "metadata": {
        "id": "mvvZFwse5UL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Spark DataFrame from the pandas DataFrame\n",
        "data = spark.createDataFrame(pdf)\n"
      ],
      "metadata": {
        "id": "u3f7bF4X54xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing: Add TotalSales column and convert InvoiceDate to DateType\n",
        "data = data.withColumn(\"TotalSales\", col(\"Quantity\") * col(\"UnitPrice\")) \\\n",
        "           .withColumn(\"InvoiceDate\", to_date(col(\"InvoiceDate\"), \"MM/dd/yyyy\"))\n",
        "\n",
        "data.createOrReplaceTempView(\"sales_data\")\n"
      ],
      "metadata": {
        "id": "CppeqK6l5X5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Country with the highest purchase\n",
        "highest_purchase = spark.sql(\"\"\"\n",
        "    SELECT Country, SUM(TotalSales) AS TotalPurchase\n",
        "    FROM sales_data\n",
        "    GROUP BY Country\n",
        "    ORDER BY TotalPurchase DESC\n",
        "    LIMIT 1\n",
        "\"\"\")\n",
        "highest_purchase.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KkegtQ-60iY",
        "outputId": "e477712e-b720-47cb-b206-e4f21df8bcad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----------------+\n",
            "|       Country|    TotalPurchase|\n",
            "+--------------+-----------------+\n",
            "|United Kingdom|8187806.363998706|\n",
            "+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Number of customers from each country\n",
        "customers_per_country = spark.sql(\"\"\"\n",
        "    SELECT Country, COUNT(DISTINCT CustomerID) AS TotalCustomers\n",
        "    FROM sales_data\n",
        "    GROUP BY Country\n",
        "    ORDER BY TotalCustomers DESC\n",
        "\"\"\")\n",
        "customers_per_country.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeSdCl5t6_qH",
        "outputId": "d994216e-38cc-4e0c-9b3a-dab2a25c724c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+\n",
            "|        Country|TotalCustomers|\n",
            "+---------------+--------------+\n",
            "| United Kingdom|          3951|\n",
            "|        Germany|            95|\n",
            "|         France|            88|\n",
            "|          Spain|            31|\n",
            "|        Belgium|            25|\n",
            "|    Switzerland|            22|\n",
            "|       Portugal|            20|\n",
            "|          Italy|            15|\n",
            "|        Finland|            12|\n",
            "|        Austria|            11|\n",
            "|         Norway|            10|\n",
            "|        Denmark|             9|\n",
            "|Channel Islands|             9|\n",
            "|      Australia|             9|\n",
            "|    Netherlands|             9|\n",
            "|         Sweden|             8|\n",
            "|         Cyprus|             8|\n",
            "|          Japan|             8|\n",
            "|         Poland|             6|\n",
            "|    Unspecified|             5|\n",
            "+---------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Maximum quantity purchased by each customer\n",
        "max_quantity_per_customer = spark.sql(\"\"\"\n",
        "    SELECT CustomerID, MAX(Quantity) AS MaxQuantity\n",
        "    FROM sales_data\n",
        "    GROUP BY CustomerID\n",
        "    ORDER BY MaxQuantity DESC\n",
        "\"\"\")\n",
        "max_quantity_per_customer.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm8KV0uP7EQ3",
        "outputId": "1590a609-f44a-4331-a626-3b42ed2bf4b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|CustomerID|MaxQuantity|\n",
            "+----------+-----------+\n",
            "|   16446.0|      80995|\n",
            "|   12346.0|      74215|\n",
            "|   13256.0|      12540|\n",
            "|       NaN|       5568|\n",
            "|   12901.0|       4800|\n",
            "|   13135.0|       4300|\n",
            "|   18087.0|       3906|\n",
            "|   14609.0|       3186|\n",
            "|   15749.0|       3114|\n",
            "|   16308.0|       3000|\n",
            "|   12931.0|       2880|\n",
            "|   16754.0|       2880|\n",
            "|   16333.0|       2592|\n",
            "|   16029.0|       2400|\n",
            "|   14646.0|       2400|\n",
            "|   14101.0|       2160|\n",
            "|   12798.0|       2040|\n",
            "|   17949.0|       1992|\n",
            "|   17450.0|       1944|\n",
            "|   15299.0|       1824|\n",
            "+----------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Max and Min sales between 01.10.24 and 15.10.24\n",
        "date_filtered_sales = spark.sql(\"\"\"\n",
        "    SELECT\n",
        "        MAX(TotalSales) AS MaxSale,\n",
        "        MIN(TotalSales) AS MinSale,\n",
        "        SUM(TotalSales) AS TotalSale\n",
        "    FROM sales_data\n",
        "    WHERE InvoiceDate BETWEEN '2024-10-01' AND '2024-10-15'\n",
        "\"\"\")\n",
        "date_filtered_sales.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiQjgXzt7Lzq",
        "outputId": "f9683f20-874d-48cd-e24e-f061ba00c722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+\n",
            "|MaxSale|MinSale|TotalSale|\n",
            "+-------+-------+---------+\n",
            "|   NULL|   NULL|     NULL|\n",
            "+-------+-------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Machine Learning with MLlib**\n",
        "Build a linear regression model to predict future sales."
      ],
      "metadata": {
        "id": "TRlV3ZLx7eOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression"
      ],
      "metadata": {
        "id": "Yc5LNr7i8u9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering: Prepare data for ML\n",
        "ml_data = data.select(\"Quantity\", \"UnitPrice\", \"TotalSales\")\n",
        "assembler = VectorAssembler(inputCols=[\"Quantity\", \"UnitPrice\"], outputCol=\"features\")\n",
        "ml_data = assembler.transform(ml_data).select(\"features\", \"TotalSales\")\n"
      ],
      "metadata": {
        "id": "Vpj0gQ138xXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split data into training and test sets\n",
        "train_data, test_data = ml_data.randomSplit([0.8, 0.2], seed=42)\n"
      ],
      "metadata": {
        "id": "EKjSZ-_J82Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Linear Regression Model\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"TotalSales\")\n",
        "lr_model = lr.fit(train_data)"
      ],
      "metadata": {
        "id": "_Z-lJx_285KS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "predictions = lr_model.transform(test_data)\n",
        "predictions.select(\"features\", \"TotalSales\", \"prediction\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh3G3QEw884r",
        "outputId": "0de12b31-78f9-49f0-f6d2-47f4610eb709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------------+-------------------+\n",
            "|      features|         TotalSales|         prediction|\n",
            "+--------------+-------------------+-------------------+\n",
            "| [-9600.0,0.0]|               -0.0|-13222.143988828493|\n",
            "| [-3114.0,2.1]| -6539.400000000001|-4284.8792177248215|\n",
            "| [-3000.0,0.0]|               -0.0| -4126.463404989572|\n",
            "|[-2000.0,1.85]|            -3700.0| -2749.482799816703|\n",
            "| [-1440.0,0.0]|               -0.0|-1976.5752669912815|\n",
            "| [-1440.0,0.0]|               -0.0|-1976.5752669912815|\n",
            "|[-1300.0,2.55]|-3314.9999999999995|-1785.2256054446457|\n",
            "| [-1092.0,0.0]|               -0.0|-1496.9848362070475|\n",
            "|  [-690.0,0.0]|               -0.0| -942.9752006459496|\n",
            "|  [-675.0,0.0]|               -0.0|  -922.303199319043|\n",
            "| [-670.0,6.75]|            -4522.5|  -919.618755016084|\n",
            "| [-624.0,2.55]|-1591.1999999999998|  -853.607412312053|\n",
            "|  [-618.0,0.0]|               -0.0| -843.7495942767978|\n",
            "|  [-590.0,0.0]|               -0.0| -805.1618584665721|\n",
            "|  [-472.0,0.0]|               -0.0| -642.5421146949064|\n",
            "|  [-391.0,0.0]|               -0.0| -530.9133075296106|\n",
            "|  [-310.0,0.0]|               -0.0|-419.28450036431485|\n",
            "|  [-220.0,0.0]|               -0.0|  -295.252492402875|\n",
            "| [-200.0,1.79]|             -358.0|-268.80525194074136|\n",
            "|  [-194.0,0.0]|               -0.0| -259.4210234362368|\n",
            "+--------------+-------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Model Metrics\n",
        "print(f\"Coefficients: {lr_model.coefficients}\")\n",
        "print(f\"Intercept: {lr_model.intercept}\")\n",
        "print(f\"RMSE: {lr_model.summary.rootMeanSquaredError}\")\n",
        "print(f\"R2 Score: {lr_model.summary.r2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PbOjjTz9Asg",
        "outputId": "0c068966-b84e-426a-8c97-c0b5c00173d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [1.378133421793776,-0.6231441194088747]\n",
            "Intercept: 7.936860391755732\n",
            "RMSE: 159.25807731171892\n",
            "R2 Score: 0.773210198440154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Output**\n",
        "\n",
        "Spark SQL Results:\n",
        "\n",
        "* Country with the Highest Purchase: Displays the country with the highest TotalSales.\n",
        "* Number of Customers per Country: Displays a breakdown of unique customers by country.\n",
        "* Maximum Quantity Purchased by Customers: Lists the maximum quantity purchased by each customer.\n",
        "* Sales Metrics within Date Range: Displays max, min, and total sales for the specified date range.\n",
        "\n",
        "Machine Learning Results:\n",
        "\n",
        "* Predicts future sales based on Quantity and UnitPrice.\n",
        "* Prints metrics such as Root Mean Squared Error (RMSE) and R² score to evaluate the model's performance."
      ],
      "metadata": {
        "id": "gWn9UbcB9qfa"
      }
    }
  ]
}